method: grid

program: "/kaggle/working/gnn-pretraining/src/finetune/finetune.py"

config_template: "/kaggle/working/gnn-pretraining/configs/finetune/template.yaml"

parameters:
  domain_name:
    values: ["Cora_NC", "CiteSeer_NC"]
  
  finetune_strategy:
    values: ["full_finetune", "linear_probe"]
  
  pretrained_scheme:
    values: 
      - "b1_from_scratch"
      - "b2_nfm"
      - "b3_nc"
      - "b4_single_domain_all"
      - "s1_multi_task_generative"
      - "s2_multi_task_contrastive"
      - "s3_all_self_supervised"
      - "s4_all_objectives"
      - "s5_all_objectives_da"
  
  task_type:
    values: ["node_classification"]
  
  batch_size:
    values: [512]
  
  epochs:
    values: [200]
  
  lr_backbone:
    distribution: categorical
    values:
      - 5e-4
      - 0.0
  
  lr_head:
    values: [1e-3]
  
  patience:
    values: [20]
  
  seed:
    values: [42, 84, 126]

parameter_combinations:
  - parameters:
      finetune_strategy: "full_finetune"
      lr_backbone: 5e-4
  
  - parameters:
      finetune_strategy: "linear_probe" 
      lr_backbone: 0.0
