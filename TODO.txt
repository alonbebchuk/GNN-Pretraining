later:
Architecture improvements (task-specific adapters)
Contrastive learning fixes (hard negative mining)
Hyperparameter optimization
Priority 1: Fix S1_42 Instability
Problem: CV=1.454 (Poor stability) despite generative tasks
Solutions:
Investigate loss balancing between NFM and Link Prediction
Check for gradient conflicts between the two generative objectives
Reduce learning rate or improve gradient clipping
Priority 2: Redesign Contrastive Learning (B3_42)
Problem: 4.9625 validation loss (16x worse than b2_42)
Solutions:
Implement hard negative mining (as noted in enhancements)
Improve augmentation strategy for better positive pairs
Reduce contrastive temperature or improve sampling
Priority 3: Optimize B4_42 Further
Opportunity: Already good (0.7881) but could approach b2_42 performance
Solutions:
Fine-tune loss balancing weights for the 5-task combination
Progressive curriculum: start with generative, add contrastive gradually

revert:
pretrain - EPOCHS = 50
run_pretrain - seeds = [42, 84, 126]
finetune - EPOCHS, PRETRAIN_FRACTION
run_finetune - seeds = [42, 84, 126]
