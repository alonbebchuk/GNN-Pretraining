{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faa4af1",
   "metadata": {},
   "source": [
    "# Task-Specific Analysis\n",
    "\n",
    "This notebook provides deep analysis of performance patterns for specific task types: Graph Classification, Node Classification, and Link Prediction.\n",
    "\n",
    "## Step 3.1: Graph Classification Analysis\n",
    "\n",
    "**Focus:** Deep analysis of graph classification performance (ENZYMES, PTC_MR)\n",
    "\n",
    "**Objectives:**\n",
    "- Extract and analyze ENZYMES and PTC_MR results\n",
    "- Compare performance patterns between datasets\n",
    "- Identify most effective pre-training schemes for graph-level tasks\n",
    "- Statistical comparison and transferable insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefe337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Define paths\n",
    "RESULTS_DIR = Path('results')\n",
    "FIGURES_DIR = Path('figures')\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Task-Specific Analysis Setup Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca249579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the aggregated and raw data\n",
    "try:\n",
    "    # Load aggregated results\n",
    "    agg_df = pd.read_csv(RESULTS_DIR / 'aggregated_results.csv')\n",
    "    \n",
    "    # Load raw experimental results\n",
    "    raw_df = pd.read_csv(RESULTS_DIR / 'raw_experimental_results.csv')\n",
    "    \n",
    "    print(f\"Loaded aggregated data: {len(agg_df)} combinations\")\n",
    "    print(f\"Loaded raw data: {len(raw_df)} experiments\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nDomains available:\")\n",
    "    print(agg_df['domain_name'].unique())\n",
    "    \n",
    "    print(\"\\nTask types:\")\n",
    "    print(agg_df['task_type'].unique())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Data files not found. Please ensure the previous analysis steps have been completed.\")\n",
    "    print(f\"Missing file: {e.filename}\")\n",
    "    agg_df = raw_df = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ddaa6a",
   "metadata": {},
   "source": [
    "## Graph Classification Data Extraction and Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract graph classification data\n",
    "if agg_df is not None:\n",
    "    # Filter for graph classification tasks\n",
    "    graph_class_domains = ['ENZYMES', 'PTC_MR']\n",
    "    graph_agg = agg_df[agg_df['domain_name'].isin(graph_class_domains)].copy()\n",
    "    graph_raw = raw_df[raw_df['domain_name'].isin(graph_class_domains)].copy()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"GRAPH CLASSIFICATION DATA OVERVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nDataset Characteristics:\")\n",
    "    for domain in graph_class_domains:\n",
    "        domain_data = graph_agg[graph_agg['domain_name'] == domain]\n",
    "        if not domain_data.empty:\n",
    "            task_type = domain_data['task_type'].iloc[0]\n",
    "            num_combinations = len(domain_data)\n",
    "            print(f\"  {domain}:\")\n",
    "            print(f\"    - Task type: {task_type}\")\n",
    "            print(f\"    - Combinations available: {num_combinations}\")\n",
    "            print(f\"    - Schemes: {sorted(domain_data['pretrained_scheme'].unique())}\")\n",
    "            print(f\"    - Strategies: {sorted(domain_data['finetune_strategy'].unique())}\")\n",
    "    \n",
    "    # Performance overview\n",
    "    print(f\"\\nPerformance Overview:\")\n",
    "    for domain in graph_class_domains:\n",
    "        domain_data = graph_agg[graph_agg['domain_name'] == domain]\n",
    "        if not domain_data.empty:\n",
    "            accuracy_stats = domain_data['accuracy_mean'].describe()\n",
    "            print(f\"\\n  {domain} Accuracy Statistics:\")\n",
    "            print(f\"    - Mean: {accuracy_stats['mean']:.4f}\")\n",
    "            print(f\"    - Std: {accuracy_stats['std']:.4f}\")\n",
    "            print(f\"    - Min: {accuracy_stats['min']:.4f}\")\n",
    "            print(f\"    - Max: {accuracy_stats['max']:.4f}\")\n",
    "            \n",
    "            # Best performing combination\n",
    "            best_idx = domain_data['accuracy_mean'].idxmax()\n",
    "            best_combo = domain_data.loc[best_idx]\n",
    "            print(f\"    - Best: {best_combo['pretrained_scheme']}-{best_combo['finetune_strategy']} ({best_combo['accuracy_mean']:.4f})\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot perform analysis without data. Please run previous steps first.\")\n",
    "    graph_agg = graph_raw = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36b52b",
   "metadata": {},
   "source": [
    "## Scheme Effectiveness Analysis for Graph Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze scheme effectiveness for graph classification\n",
    "if graph_agg is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SCHEME EFFECTIVENESS FOR GRAPH CLASSIFICATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculate baseline performance for each domain\n",
    "    baseline_performance = {}\n",
    "    for domain in graph_class_domains:\n",
    "        baseline_data = graph_agg[\n",
    "            (graph_agg['domain_name'] == domain) & \n",
    "            (graph_agg['pretrained_scheme'] == 'b1')\n",
    "        ]\n",
    "        if not baseline_data.empty:\n",
    "            baseline_performance[domain] = baseline_data['accuracy_mean'].mean()\n",
    "    \n",
    "    print(f\"\\nBaseline Performance (b1):\")\n",
    "    for domain, perf in baseline_performance.items():\n",
    "        print(f\"  {domain}: {perf:.4f}\")\n",
    "    \n",
    "    # Analyze scheme performance and improvement over baseline\n",
    "    scheme_analysis = []\n",
    "    schemes = sorted(graph_agg['pretrained_scheme'].unique())\n",
    "    \n",
    "    for domain in graph_class_domains:\n",
    "        if domain not in baseline_performance:\n",
    "            continue\n",
    "            \n",
    "        baseline_perf = baseline_performance[domain]\n",
    "        domain_data = graph_agg[graph_agg['domain_name'] == domain]\n",
    "        \n",
    "        for scheme in schemes:\n",
    "            scheme_data = domain_data[domain_data['pretrained_scheme'] == scheme]\n",
    "            if not scheme_data.empty:\n",
    "                mean_acc = scheme_data['accuracy_mean'].mean()\n",
    "                std_acc = scheme_data['accuracy_mean'].std()\n",
    "                improvement = ((mean_acc - baseline_perf) / baseline_perf) * 100\n",
    "                \n",
    "                # Calculate rank within domain\n",
    "                domain_scheme_means = domain_data.groupby('pretrained_scheme')['accuracy_mean'].mean()\n",
    "                rank = domain_scheme_means.rank(ascending=False)[scheme]\n",
    "                \n",
    "                scheme_analysis.append({\n",
    "                    'domain': domain,\n",
    "                    'scheme': scheme,\n",
    "                    'mean_accuracy': mean_acc,\n",
    "                    'std_accuracy': std_acc,\n",
    "                    'improvement_pct': improvement,\n",
    "                    'rank_in_domain': rank,\n",
    "                    'num_combinations': len(scheme_data)\n",
    "                })\n",
    "    \n",
    "    scheme_df = pd.DataFrame(scheme_analysis)\n",
    "    \n",
    "    print(f\"\\nScheme Performance Analysis:\")\n",
    "    print(scheme_df.round(4))\n",
    "    \n",
    "    # Best schemes per domain\n",
    "    print(f\"\\nBest Schemes per Domain:\")\n",
    "    for domain in graph_class_domains:\n",
    "        domain_schemes = scheme_df[scheme_df['domain'] == domain]\n",
    "        if not domain_schemes.empty:\n",
    "            best_scheme = domain_schemes.loc[domain_schemes['improvement_pct'].idxmax()]\n",
    "            print(f\"  {domain}: {best_scheme['scheme']} (+{best_scheme['improvement_pct']:.2f}%, rank {best_scheme['rank_in_domain']:.0f})\")\n",
    "    \n",
    "    # Save the analysis results\n",
    "    scheme_df.to_csv(RESULTS_DIR / 'graph_classification_analysis.csv', index=False)\n",
    "    print(f\"\\nAnalysis saved to: {RESULTS_DIR / 'graph_classification_analysis.csv'}\")\n",
    "    \n",
    "else:\n",
    "    scheme_df = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3ab07",
   "metadata": {},
   "source": [
    "## Cross-Dataset Consistency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69169306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze consistency between ENZYMES and PTC_MR\n",
    "if scheme_df is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CROSS-DATASET CONSISTENCY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create pivot table for easier comparison\n",
    "    pivot_improvement = scheme_df.pivot(index='scheme', columns='domain', values='improvement_pct')\n",
    "    pivot_rank = scheme_df.pivot(index='scheme', columns='domain', values='rank_in_domain')\n",
    "    \n",
    "    print(f\"\\nImprovement Percentage by Scheme:\")\n",
    "    print(pivot_improvement.round(2))\n",
    "    \n",
    "    print(f\"\\nRank by Scheme (1 = best):\")\n",
    "    print(pivot_rank.round(0))\n",
    "    \n",
    "    # Calculate correlation between datasets\n",
    "    if 'ENZYMES' in pivot_improvement.columns and 'PTC_MR' in pivot_improvement.columns:\n",
    "        # Remove NaN values for correlation calculation\n",
    "        valid_data = pivot_improvement.dropna()\n",
    "        \n",
    "        if len(valid_data) > 1:\n",
    "            # Performance correlation\n",
    "            perf_corr, perf_p = spearmanr(valid_data['ENZYMES'], valid_data['PTC_MR'])\n",
    "            print(f\"\\nPerformance Correlation:\")\n",
    "            print(f\"  Spearman correlation: {perf_corr:.3f} (p={perf_p:.3f})\")\n",
    "            \n",
    "            # Rank correlation\n",
    "            valid_ranks = pivot_rank.dropna()\n",
    "            if len(valid_ranks) > 1:\n",
    "                rank_corr, rank_p = spearmanr(valid_ranks['ENZYMES'], valid_ranks['PTC_MR'])\n",
    "                print(f\"  Rank correlation: {rank_corr:.3f} (p={rank_p:.3f})\")\n",
    "            \n",
    "            # Identify consistent performers\n",
    "            print(f\"\\nConsistent Top Performers (top 3 in both datasets):\")\n",
    "            enzymes_top3 = valid_ranks['ENZYMES'].nsmallest(3).index\n",
    "            ptc_top3 = valid_ranks['PTC_MR'].nsmallest(3).index\n",
    "            consistent_top = set(enzymes_top3) & set(ptc_top3)\n",
    "            \n",
    "            if consistent_top:\n",
    "                for scheme in consistent_top:\n",
    "                    e_rank = valid_ranks.loc[scheme, 'ENZYMES']\n",
    "                    p_rank = valid_ranks.loc[scheme, 'PTC_MR']\n",
    "                    e_imp = valid_data.loc[scheme, 'ENZYMES']\n",
    "                    p_imp = valid_data.loc[scheme, 'PTC_MR']\n",
    "                    print(f\"  {scheme}: ENZYMES rank {e_rank:.0f} (+{e_imp:.2f}%), PTC_MR rank {p_rank:.0f} (+{p_imp:.2f}%)\")\n",
    "            else:\n",
    "                print(f\"  No schemes consistently in top 3 for both datasets\")\n",
    "    \n",
    "else:\n",
    "    pivot_improvement = pivot_rank = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0cf53",
   "metadata": {},
   "source": [
    "## Graph Classification Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations for graph classification analysis\n",
    "if scheme_df is not None and graph_raw is not None:\n",
    "    print(\"Creating Graph Classification Visualizations...\")\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # 1. Performance comparison by scheme\n",
    "    plt.subplot(2, 3, 1)\n",
    "    if pivot_improvement is not None:\n",
    "        schemes = pivot_improvement.index\n",
    "        x_pos = np.arange(len(schemes))\n",
    "        width = 0.35\n",
    "        \n",
    "        enzymes_data = pivot_improvement['ENZYMES'].fillna(0)\n",
    "        ptc_data = pivot_improvement['PTC_MR'].fillna(0)\n",
    "        \n",
    "        bars1 = plt.bar(x_pos - width/2, enzymes_data, width, label='ENZYMES', alpha=0.8)\n",
    "        bars2 = plt.bar(x_pos + width/2, ptc_data, width, label='PTC_MR', alpha=0.8)\n",
    "        \n",
    "        plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "        plt.xlabel('Pre-training Scheme')\n",
    "        plt.ylabel('Improvement (%)')\n",
    "        plt.title('Performance Improvement by Scheme')\n",
    "        plt.xticks(x_pos, schemes, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Correlation scatter plot\n",
    "    plt.subplot(2, 3, 2)\n",
    "    if pivot_improvement is not None and 'ENZYMES' in pivot_improvement.columns and 'PTC_MR' in pivot_improvement.columns:\n",
    "        valid_data = pivot_improvement.dropna()\n",
    "        if not valid_data.empty:\n",
    "            plt.scatter(valid_data['ENZYMES'], valid_data['PTC_MR'], alpha=0.7, s=100)\n",
    "            \n",
    "            # Add labels for each point\n",
    "            for idx, scheme in enumerate(valid_data.index):\n",
    "                plt.annotate(scheme, (valid_data.loc[scheme, 'ENZYMES'], valid_data.loc[scheme, 'PTC_MR']),\n",
    "                           xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "            \n",
    "            # Add diagonal line\n",
    "            min_val = min(valid_data.min())\n",
    "            max_val = max(valid_data.max())\n",
    "            plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7, label='Perfect correlation')\n",
    "            \n",
    "            plt.axhline(y=0, color='red', linestyle=':', alpha=0.7)\n",
    "            plt.axvline(x=0, color='red', linestyle=':', alpha=0.7)\n",
    "            plt.xlabel('ENZYMES Improvement (%)')\n",
    "            plt.ylabel('PTC_MR Improvement (%)')\n",
    "            plt.title('Cross-Dataset Performance Correlation')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Performance distribution by dataset\n",
    "    plt.subplot(2, 3, 3)\n",
    "    enzymes_data = graph_raw[graph_raw['domain_name'] == 'ENZYMES']['accuracy']\n",
    "    ptc_data = graph_raw[graph_raw['domain_name'] == 'PTC_MR']['accuracy']\n",
    "    \n",
    "    plt.hist(enzymes_data, alpha=0.6, label='ENZYMES', bins=20, density=True)\n",
    "    plt.hist(ptc_data, alpha=0.6, label='PTC_MR', bins=20, density=True)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Performance Distribution Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Box plot by scheme\n",
    "    plt.subplot(2, 3, 4)\n",
    "    graph_raw_plot = graph_raw.copy()\n",
    "    sns.boxplot(data=graph_raw_plot, x='pretrained_scheme', y='accuracy', hue='domain_name')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Accuracy Distribution by Scheme and Dataset')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Best scheme visualization\n",
    "    plt.subplot(2, 3, 5)\n",
    "    best_schemes_data = []\n",
    "    for domain in graph_class_domains:\n",
    "        domain_data = scheme_df[scheme_df['domain'] == domain]\n",
    "        if not domain_data.empty:\n",
    "            best_scheme = domain_data.loc[domain_data['improvement_pct'].idxmax()]\n",
    "            best_schemes_data.append({\n",
    "                'domain': domain,\n",
    "                'best_scheme': best_scheme['scheme'],\n",
    "                'improvement': best_scheme['improvement_pct']\n",
    "            })\n",
    "    \n",
    "    if best_schemes_data:\n",
    "        best_df = pd.DataFrame(best_schemes_data)\n",
    "        bars = plt.bar(best_df['domain'], best_df['improvement'])\n",
    "        plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add scheme labels on bars\n",
    "        for bar, scheme in zip(bars, best_df['best_scheme']):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -1),\n",
    "                    scheme, ha='center', va='bottom' if height > 0 else 'top', fontsize=10)\n",
    "        \n",
    "        plt.xlabel('Dataset')\n",
    "        plt.ylabel('Best Improvement (%)')\n",
    "        plt.title('Best Performing Scheme per Dataset')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Multi-class vs Binary comparison\n",
    "    plt.subplot(2, 3, 6)\n",
    "    dataset_performance = graph_agg.groupby('domain_name')['accuracy_mean'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    bars = plt.bar(dataset_performance['domain_name'], dataset_performance['mean'], \n",
    "                  yerr=dataset_performance['std'], capsize=5, alpha=0.8)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, mean_val in zip(bars, dataset_performance['mean']):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                f'{mean_val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Mean Accuracy')\n",
    "    plt.title('Multi-class vs Binary Classification Performance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'graph_classification_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Graph classification visualization saved to: analysis/figures/graph_classification_comparison.png\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot create visualizations without data. Please ensure previous steps completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb2915",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary and recommendations for graph classification\n",
    "if scheme_df is not None:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GRAPH CLASSIFICATION SUMMARY AND RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Key findings\n",
    "    print(\"\\nKEY FINDINGS:\")\n",
    "    \n",
    "    # Best overall schemes\n",
    "    overall_improvement = scheme_df.groupby('scheme')['improvement_pct'].mean().sort_values(ascending=False)\n",
    "    print(f\"\\n1. BEST PERFORMING SCHEMES (average improvement):\")\n",
    "    for i, (scheme, improvement) in enumerate(overall_improvement.head(3).items()):\n",
    "        print(f\"   {i+1}. {scheme}: {improvement:.2f}%\")\n",
    "    \n",
    "    # Dataset-specific findings\n",
    "    print(f\"\\n2. DATASET-SPECIFIC INSIGHTS:\")\n",
    "    for domain in graph_class_domains:\n",
    "        domain_data = scheme_df[scheme_df['domain'] == domain]\n",
    "        if not domain_data.empty:\n",
    "            best = domain_data.loc[domain_data['improvement_pct'].idxmax()]\n",
    "            worst = domain_data.loc[domain_data['improvement_pct'].idxmin()]\n",
    "            print(f\"   {domain}:\")\n",
    "            print(f\"     - Best: {best['scheme']} (+{best['improvement_pct']:.2f}%)\")\n",
    "            print(f\"     - Worst: {worst['scheme']} ({worst['improvement_pct']:.2f}%)\")\n",
    "            print(f\"     - Range: {best['improvement_pct'] - worst['improvement_pct']:.2f}%\")\n",
    "    \n",
    "    # Consistency analysis\n",
    "    if pivot_improvement is not None and len(pivot_improvement.columns) >= 2:\n",
    "        valid_data = pivot_improvement.dropna()\n",
    "        if len(valid_data) > 1:\n",
    "            corr_coef = np.corrcoef(valid_data.iloc[:, 0], valid_data.iloc[:, 1])[0, 1]\n",
    "            print(f\"\\n3. CROSS-DATASET CONSISTENCY:\")\n",
    "            print(f\"   - Performance correlation: {corr_coef:.3f}\")\n",
    "            print(f\"   - Consistency level: {'High' if abs(corr_coef) > 0.7 else 'Moderate' if abs(corr_coef) > 0.4 else 'Low'}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n4. RECOMMENDATIONS FOR GRAPH CLASSIFICATION:\")\n",
    "    \n",
    "    top_3_schemes = overall_improvement.head(3).index.tolist()\n",
    "    print(f\"   - Recommended schemes: {', '.join(top_3_schemes)}\")\n",
    "    \n",
    "    # Task-specific recommendations\n",
    "    enzymes_best = scheme_df[scheme_df['domain'] == 'ENZYMES'].loc[scheme_df[scheme_df['domain'] == 'ENZYMES']['improvement_pct'].idxmax(), 'scheme']\n",
    "    ptc_best = scheme_df[scheme_df['domain'] == 'PTC_MR'].loc[scheme_df[scheme_df['domain'] == 'PTC_MR']['improvement_pct'].idxmax(), 'scheme']\n",
    "    \n",
    "    print(f\"   - For multi-class graph classification (similar to ENZYMES): Use {enzymes_best}\")\n",
    "    print(f\"   - For binary graph classification (similar to PTC_MR): Use {ptc_best}\")\n",
    "    \n",
    "    # Strategy recommendations\n",
    "    if graph_agg is not None:\n",
    "        strategy_performance = graph_agg.groupby('finetune_strategy')['accuracy_mean'].mean()\n",
    "        best_strategy = strategy_performance.idxmax()\n",
    "        print(f\"   - Recommended fine-tuning strategy: {best_strategy}\")\n",
    "    \n",
    "    print(f\"\\nAnalysis complete! Results saved to: analysis/results/graph_classification_analysis.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot generate recommendations without completed analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f09f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
